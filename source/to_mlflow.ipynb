{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import gymnasium\n",
    "\n",
    "from stable_baselines3 import DDPG, SAC, TD3, PPO, A2C\n",
    "from stable_baselines3.common.logger import KVWriter, Logger, Video\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "TZ = timezone('Europe/Moscow')\n",
    "models = {'DDPG':DDPG, 'SAC':SAC, 'TD3':TD3, 'PPO':PPO, 'A2C':A2C}\n",
    "activations = {'ReLU':torch.nn.ReLU, 'Tanh':torch.nn.Tanh}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLflowCheckpointCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model every ``save_freq`` calls\n",
    "    to ``env.step()``.\n",
    "    By default, it only saves model checkpoints,\n",
    "    you need to pass ``save_replay_buffer=True``,\n",
    "    and ``save_vecnormalize=True`` to also save replay buffer checkpoints\n",
    "    and normalization statistics checkpoints.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "      When using multiple environments, each call to  ``env.step()``\n",
    "      will effectively correspond to ``n_envs`` steps.\n",
    "      To account for that, you can use ``save_freq = max(save_freq // n_envs, 1)``\n",
    "\n",
    "    :param save_freq: Save checkpoints every ``save_freq`` call of the callback.\n",
    "    :param save_path: Path to the folder where the model will be saved.\n",
    "    :param save_replay_buffer: Save the model replay buffer\n",
    "    :param save_vecnormalize: Save the ``VecNormalize`` statistics\n",
    "    :param verbose: Verbosity level: 0 for no output, 2 for indicating when saving model checkpoint\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gymnasium.Env,\n",
    "        save_freq: int,\n",
    "        save_path: str,\n",
    "        save_replay_buffer: bool = False,\n",
    "        save_vecnormalize: bool = False,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "        super().__init__(verbose)\n",
    "        self.eval_env = eval_env\n",
    "        self.save_freq = save_freq\n",
    "        self.save_path = save_path\n",
    "        self.save_replay_buffer = save_replay_buffer\n",
    "        self.save_vecnormalize = save_vecnormalize\n",
    "\n",
    "    def _checkpoint_path(self, checkpoint_type: str = \"\") -> str:\n",
    "        return f'{checkpoint_type}{self.save_path}/{self.n_calls}'\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.save_freq == 0:\n",
    "\n",
    "            save_path = self._checkpoint_path()\n",
    "            os.mkdir(save_path)\n",
    "            model_path = save_path + '/model.zip'\n",
    "            self.model.save(model_path)\n",
    "            mlflow.log_artifact(model_path, save_path + '/sb3')\n",
    "\n",
    "            if self.verbose >= 2:\n",
    "                print(f\"Saving model checkpoint to {save_path}\")\n",
    "\n",
    "            if self.save_replay_buffer and hasattr(self.model, \"replay_buffer\") and self.model.replay_buffer is not None:\n",
    "                # If model has a replay buffer, save it too\n",
    "\n",
    "                replay_buffer_path = save_path + \"/replay_buffer.pkl\"\n",
    "                self.model.save_replay_buffer(replay_buffer_path)  # type: ignore[attr-defined]\n",
    "                mlflow.log_artifact(replay_buffer_path, save_path + '/replay_buffer')\n",
    "                if self.verbose > 1:\n",
    "                    print(f\"Saving model replay buffer checkpoint to {replay_buffer_path}\")\n",
    "\n",
    "            if self.save_vecnormalize and self.model.get_vec_normalize_env() is not None:\n",
    "                # Save the VecNormalize statistics\n",
    "                vec_normalize_path = save_path + \"/vecnormalize.pkl\"\n",
    "                self.model.get_vec_normalize_env().save(vec_normalize_path)  # type: ignore[union-attr]\n",
    "                mlflow.log_artifact(vec_normalize_path, save_path + '/vecnormalize')\n",
    "                if self.verbose >= 2:\n",
    "                    print(f\"Saving model VecNormalize to {vec_normalize_path}\")\n",
    "\n",
    "            \n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLflowOutputFormat(KVWriter):\n",
    "    \"\"\"\n",
    "    Dumps key/value pairs into MLflow's numeric format.\n",
    "    \"\"\"\n",
    "\n",
    "    def write(\n",
    "        self,\n",
    "        key_values: Dict[str, Any],\n",
    "        key_excluded: Dict[str, Union[str, Tuple[str, ...]]],\n",
    "        step: int = 0,\n",
    "    ) -> None:\n",
    "\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())\n",
    "        ):\n",
    "\n",
    "            if excluded is not None and \"mlflow\" in excluded:\n",
    "                continue\n",
    "\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    mlflow.log_metric(key, value, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"http://192.168.0.206:2670\" \n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Pendulum-v1_SAC_exp_0109_145419\n"
     ]
    }
   ],
   "source": [
    "exp_params = {\n",
    "    'env_name': 'Pendulum-v1',\n",
    "    'algorithm_name': 'SAC',\n",
    "    'exp_id': f'exp_{datetime.now(TZ).strftime(\"%d%m_%H%M%S\")}',\n",
    "    'seed': 21,\n",
    "    'net': {\n",
    "        'activation': 'ReLU',\n",
    "        'pi': [256, 256],\n",
    "        'qf': [256, 256],\n",
    "        'vf': None,\n",
    "    },\n",
    "    'training': {\n",
    "        'iteration_count': 1,\n",
    "        'episode_count': 1000,\n",
    "        'policy': 'MlpPolicy',\n",
    "        'learning_rate': 0.003,\n",
    "        'buffer_size': 1000000,\n",
    "        'learning_starts': 100,\n",
    "        'batch_size': 256,\n",
    "        'tau': 0.005,\n",
    "        'gamma': 0.99,\n",
    "        'verbose': 0,\n",
    "        'device': device,\n",
    "    },\n",
    "    'validation': {\n",
    "        'validate_agent_every_n_eps': 300,\n",
    "        'log_interval': 10\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'episode_count': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "loggers = Logger(\n",
    "    folder=None,\n",
    "    output_formats=[MLflowOutputFormat()],\n",
    ")\n",
    "\n",
    "policy_kwargs = dict(activation_fn = activations[exp_params['net']['activation']],\n",
    "                     net_arch = dict(pi=exp_params['net']['pi'], qf=exp_params['net']['qf']))\n",
    "\n",
    "exp_name = 'test_' + exp_params['env_name'] + '_' + exp_params['algorithm_name'] + '_' + exp_params['exp_id']\n",
    "print(exp_name)\n",
    "os.mkdir(exp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VideoRecord(eval_env: gymnasium.Env, path: str):\n",
    "    \n",
    "    #Video\n",
    "    load_model = models[exp_params['algorithm_name']].load(path+'model.zip', eval_env)\n",
    "\n",
    "    screens = []\n",
    "    def grab_screens(_locals: Dict[str, Any], _globals: Dict[str, Any]) -> None:\n",
    "        screen = eval_env.render()\n",
    "        screens.append(screen)\n",
    "\n",
    "    evaluate_policy(\n",
    "        load_model,\n",
    "        eval_env,\n",
    "        callback=grab_screens,\n",
    "        n_eval_episodes=1,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    \n",
    "    video_path = path + 'agent.mp4'\n",
    "    clip = ImageSequenceClip(screens, fps=30)\n",
    "    clip.write_videofile(video_path)\n",
    "    return 'agent.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/01 14:54:23 INFO mlflow.tracking.fluent: Experiment with name 'test_Pendulum-v1_SAC_exp_0109_145419' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2df419959d543aea1b979ad1bb0762e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/01 14:54:37 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.2+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_Pendulum-v1_SAC_exp_0109_145419/300/agent.mp4.\n",
      "Moviepy - Writing video test_Pendulum-v1_SAC_exp_0109_145419/300/agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_Pendulum-v1_SAC_exp_0109_145419/300/agent.mp4\n",
      "Moviepy - Building video test_Pendulum-v1_SAC_exp_0109_145419/600/agent.mp4.\n",
      "Moviepy - Writing video test_Pendulum-v1_SAC_exp_0109_145419/600/agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_Pendulum-v1_SAC_exp_0109_145419/600/agent.mp4\n",
      "Moviepy - Building video test_Pendulum-v1_SAC_exp_0109_145419/900/agent.mp4.\n",
      "Moviepy - Writing video test_Pendulum-v1_SAC_exp_0109_145419/900/agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_Pendulum-v1_SAC_exp_0109_145419/900/agent.mp4\n",
      "Moviepy - Building video test_Pendulum-v1_SAC_exp_0109_145419/agent.mp4.\n",
      "Moviepy - Writing video test_Pendulum-v1_SAC_exp_0109_145419/agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_Pendulum-v1_SAC_exp_0109_145419/agent.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_callback = MLflowCheckpointCallback(\n",
    "  eval_env=gymnasium.make(exp_params['env_name'], render_mode=\"rgb_array\"),\n",
    "  save_freq=exp_params['validation']['validate_agent_every_n_eps'],\n",
    "  save_path=exp_name,\n",
    "  verbose=0,\n",
    ")\n",
    "\n",
    "exp = mlflow.set_experiment(exp_name)\n",
    "exp.experiment_id\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model = models[exp_params['algorithm_name']](exp_params['training']['policy'], \n",
    "                                                 exp_params['env_name'],\n",
    "                                                 policy_kwargs=policy_kwargs,\n",
    "                                                 learning_rate=exp_params['training']['learning_rate'],\n",
    "                                                 buffer_size=exp_params['training']['buffer_size'],\n",
    "                                                 learning_starts=exp_params['training']['learning_starts'],\n",
    "                                                 batch_size=exp_params['training']['batch_size'],\n",
    "                                                 tau=exp_params['training']['tau'],\n",
    "                                                 gamma=exp_params['training']['gamma'],\n",
    "                                                 verbose=exp_params['training']['verbose'],\n",
    "                                                 device=device,\n",
    "                                                 )\n",
    "    \n",
    "    mlflow.log_dict(exp_params, exp_name + '/parameters.json')\n",
    "    mlflow.log_params(exp_params)\n",
    "    \n",
    "    model.set_logger(loggers)\n",
    "    model.learn(total_timesteps=exp_params['training']['episode_count'],\n",
    "                log_interval=exp_params['validation']['log_interval'],\n",
    "                callback = save_callback,\n",
    "                progress_bar=True\n",
    "                )\n",
    "    \n",
    "    model.save(exp_name + '/model.zip')\n",
    "    \n",
    "    mlflow.pytorch.log_model(model.actor, exp_name + '/actor')\n",
    "\n",
    "    mlflow.log_artifact(exp_name + '/model.zip', exp_name + '/sb3')\n",
    "\n",
    "    dirs = os.listdir(exp_name)\n",
    "    dirs = [exp_name+'/'+ f + '/' for f in dirs if os.path.isdir(exp_name+'/'+f)]\n",
    "    dirs.append(exp_name+'/')\n",
    "    for dir in dirs:\n",
    "      video = VideoRecord(model.env, dir)\n",
    "      mlflow.log_artifact(dir + video, dir + 'video')\n",
    "\n",
    "#model_uri = f\"runs:/{run.info.run_id}/{exp_params['algorithm_name']}\"\n",
    "#print(model_uri)\n",
    "#mv = mlflow.register_model(model_uri, exp_name)\n",
    "\n",
    "\n",
    "shutil.rmtree(os.path.join(exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment(\"37\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_loc = f'{experiment.artifact_location}/f71979d6fa3e4fe3a1caa8adae3714c9/artifacts/{experiment.name}/'\n",
    "art_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.artifacts.download_artifacts(artifact_uri=art_loc + 'sb3/model.zip', dst_path=exp_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_conda_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
